{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent Itemset and Association Rule Mining using Apriori and FPGrowth Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> By Smit Doshi (001475186) </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XNYy0cT4cVBB"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from spmf import Spmf\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the data & reading the tweets line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fvV_VKMzcjat"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"There\\'s no science behind the term behavioural fatigue.\" - Professor Robert West, member of the government\\'s scientific pandemic influenza group on behaviours Watch @lewis_goodall\\'s report into why the UK didn\\'t lockdown sooner https://bbc.in/2X9WJ5O #Newsnight\\n',\n",
       " 'Bare tse di woke di tsena mo lockdown....\\n',\n",
       " 'My boss o ntse rude hela mo nna ke ipotsa a nne o akanya gore ke nna Dr Masupu nne? (Lockdown stay home)\\n',\n",
       " 'Thank you for this prize @realmemobiles @MadhavSheth1 I am glad the team had organised a @PUBG tournament in this lockdown And this journey from qualifiers to winning the finals was great fun , and i was overwhelmed on winning these Wish to see these type games again \\n',\n",
       " 'Are we out of lockdown\\n',\n",
       " '#NowPlaying @originalkoffee - LOCKDOWN @RobboRanx @RobboRanxRadio #Dancehall360\\n',\n",
       " 'Christians Get Around Newsom Church Lockdown: Over 5,000 Show Up on CA Beach To Worship \\n',\n",
       " \"it took a lot of time for me to adjust to this lifestyle and I don't think I can suddenly switch back to what it was like before lockdown\\n\",\n",
       " 'E masepa lockdown... \\n',\n",
       " \"4,825 new cases in 24 hours in Los Angeles County, California, alone, yesterday: more than half of the state's daily total #new cases. California reopened too quickly and too haphazardly. At minimum, LA County needs a lockdown. http://publichealth.lacounty.gov/media/Coronavirus/data/index.htm https://www.cdph.ca.gov/Programs/CID/DCDC/PublishingImages/COVID-19/CA_COVID-19_ByTheNumbers_July29.png\\n\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = open('Dataset.txt',mode='r').readlines()\n",
    "raw_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the dataset \n",
    "##### Removing all punctuations from the end of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IeN1AUTHedKC",
    "outputId": "ad776bd2-edc3-4293-8906-d20bbf4ad6aa"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "#punc = '!\"$%&\\'()*+,-.;<=>?[\\\\]^_`{|}~'\n",
    "\n",
    "for line in raw_data:\n",
    "    line = line.lower()\n",
    "    line = line.replace('\\n','')\n",
    "    line = line.replace('.','')\n",
    "    line = line.encode('ascii',errors='ignore')\n",
    "    line = line.decode()\n",
    "    line = line.replace('  ','')\n",
    "    \n",
    "    try:\n",
    "         while line[-1] not in string.ascii_letters:\n",
    "                try:\n",
    "                    line = line.rstrip(\" \")\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    line = line.rstrip(string.punctuation)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    line = line.rstrip(string.digits)\n",
    "                except:\n",
    "                    pass\n",
    "    except:\n",
    "        pass\n",
    "    results.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6LgAwzZJxiG",
    "outputId": "160ab6a1-3c56-4be4-e06e-00ed99d9461b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"there\\'s no science behind the term behavioural fatigue\" - professor robert west, member of the government\\'s scientific pandemic influenza group on behaviours watch @lewis_goodall\\'s report into why the uk didn\\'t lockdown sooner https://bbcin/2x9wj5o #newsnight',\n",
       " 'bare tse di woke di tsena mo lockdown',\n",
       " 'my boss o ntse rude hela mo nna ke ipotsa a nne o akanya gore ke nna dr masupu nne? (lockdown stay home',\n",
       " 'thank you for this prize @realmemobiles @madhavsheth1 i am glad the team had organised a @pubg tournament in this lockdown and this journey from qualifiers to winning the finals was great fun , and i was overwhelmed on winning these wish to see these type games again',\n",
       " 'are we out of lockdown',\n",
       " '#nowplaying @originalkoffee - lockdown @robboranx @robboranxradio #dancehall',\n",
       " 'christians get around newsom church lockdown: over 5,000 show up on ca beach to worship',\n",
       " \"it took a lot of time for me to adjust to this lifestyle and i don't think i can suddenly switch back to what it was like before lockdown\",\n",
       " 'e masepa lockdown',\n",
       " \"4,825 new cases in 24 hours in los angeles county, california, alone, yesterday: more than half of the state's daily total #new cases california reopened too quickly and too haphazardly at minimum, la county needs a lockdown http://publichealthlacountygov/media/coronavirus/data/indexhtm https://wwwcdphcagov/programs/cid/dcdc/publishingimages/covid-19/ca_covid-19_bythenumbers_july29png\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the dictionary of all the unique words used in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Sd8a9VPMKhG",
    "outputId": "a154aa94-1a60-4678-b84e-37648005fad6"
   },
   "outputs": [],
   "source": [
    "final_dict = {}\n",
    "m = 0\n",
    "for i in range(0,len(results)):\n",
    "    for word in results[i].split(\" \"):\n",
    "        if word not in final_dict.keys():\n",
    "            final_dict[word] = m + 1\n",
    "            m = m + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of unique words in our dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "As3iA0qPNpl_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175662"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"there\\'s', 1),\n",
       " ('no', 2),\n",
       " ('science', 3),\n",
       " ('behind', 4),\n",
       " ('the', 5),\n",
       " ('term', 6),\n",
       " ('behavioural', 7),\n",
       " ('fatigue\"', 8),\n",
       " ('-', 9),\n",
       " ('professor', 10),\n",
       " ('robert', 11),\n",
       " ('west,', 12),\n",
       " ('member', 13),\n",
       " ('of', 14),\n",
       " (\"government's\", 15),\n",
       " ('scientific', 16),\n",
       " ('pandemic', 17),\n",
       " ('influenza', 18),\n",
       " ('group', 19),\n",
       " ('on', 20)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(final_dict.items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing words with their corresponding number from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-LPI7mmQ7bi",
    "outputId": "176d1621-1b95-452d-a03a-746952943e01"
   },
   "outputs": [],
   "source": [
    "output_list = []\n",
    "\n",
    "for i in range(0,len(results)):\n",
    "    line_list=[]\n",
    "    for word in results[i].split(\" \"):\n",
    "        line_list.append(final_dict[word])\n",
    "        line_list = list(set(line_list))\n",
    "        line_list.sort()\n",
    "    output_list.append(' '.join([str(elem) for elem in line_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32',\n",
       " '29 33 34 35 36 37 38',\n",
       " '38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57',\n",
       " '5 20 29 48 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91',\n",
       " '14 29 92 93 94',\n",
       " '9 29 95 96 97 98 99',\n",
       " '20 78 100 101 102 103 104 105 106 107 108 109 110 111 112',\n",
       " '14 29 48 60 61 65 74 78 81 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128',\n",
       " '29 129 130',\n",
       " '5 14 29 48 73 74 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing it to the text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qblCJiCCipvp"
   },
   "outputs": [],
   "source": [
    "new_data = open(r\"new_dataset.txt\",\"w\")\n",
    "for line in output_list:\n",
    "    new_data.write(line + str('\\n'))\n",
    "new_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetKey(val,dictionary = final_dict):\n",
    "    for key, value in dictionary.items():\n",
    "        if val == value:\n",
    "             return key\n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/Users/smitdoshi/Downloads/spmf.jar\n",
      "=============  APRIORI - STATS =============\n",
      " Candidates count : 28\n",
      " The algorithm stopped at size 3\n",
      " Frequent itemsets count : 9\n",
      " Maximum memory usage : 80.13859558105469 mb\n",
      " Total time ~ 503 ms\n",
      "===================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apriori = Spmf(algorithm_name='Apriori',arguments=[0.3],input_filename='new_dataset.txt',\n",
    "               output_filename='apriori_output.txt',spmf_bin_location_dir='/Users/smitdoshi/Downloads/')\n",
    "apriori.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is the dataframe that shows the words having Support more than 30 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-c5119ba2bf67>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.Words[index] = GetKey(int(word))\n",
      "<ipython-input-13-c5119ba2bf67>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.Words[index] = GetKey(int(word.split(',')[0])) + \",\" + GetKey(int(word.split(',')[1]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>78386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>48079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the,lockdown</td>\n",
       "      <td>40027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>39495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>33683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Words  Support\n",
       "0      lockdown    78386\n",
       "1           the    48079\n",
       "2  the,lockdown    40027\n",
       "3            to    39495\n",
       "4            in    33683"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('apriori_output.txt', sep='#',header=None)\n",
    "sup = df[1].str.split(\":\", n = 1, expand = True)\n",
    "df['Support'] =sup[1]\n",
    "df.rename(columns = {0:'Words'}, inplace = True)\n",
    "df.drop(1,axis=1,inplace=True)\n",
    "df.Support = df.Support.astype(int)\n",
    "df.Words = df.Words.str.rstrip()\n",
    "df.Words = df.Words.str.replace(\" \",\",\")\n",
    "for index,word in df.Words.items():\n",
    "    if ',' in word:\n",
    "        df.Words[index] = GetKey(int(word.split(',')[0])) + \",\" + GetKey(int(word.split(',')[1]))\n",
    "    else:\n",
    "        df.Words[index] = GetKey(int(word))\n",
    "df = df.sort_values('Support',ascending=False,ignore_index=True)\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the FPGrowth Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/Users/smitdoshi/Downloads/spmf.jar\n",
      "=============  FP-GROWTH 2.42 - STATS =============\n",
      " Transactions count from database : 95488\n",
      " Max memory usage: 85.37606811523438 mb \n",
      " Frequent itemsets count : 4\n",
      " Total time ~ 576 ms\n",
      "===================================================\n",
      "=============  ASSOCIATION RULE GENERATION v2.19- STATS =============\n",
      " Number of association rules generated : 2\n",
      " Total time ~ 0 ms\n",
      "===================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fpgrowth = Spmf(algorithm_name='FPGrowth_association_rules_with_lift',arguments=[0.4,0,1],\n",
    "                input_filename='new_dataset.txt',output_filename='fpgrowth_output.txt',spmf_bin_location_dir='/Users/smitdoshi/Downloads/')\n",
    "fpgrowth.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/Users/smitdoshi/Downloads/spmf.jar\n",
      "=============  FP-GROWTH 2.42 - STATS =============\n",
      " Transactions count from database : 95488\n",
      " Max memory usage: 84.15547180175781 mb \n",
      " Frequent itemsets count : 14\n",
      " Total time ~ 644 ms\n",
      "===================================================\n",
      "=============  ASSOCIATION RULE GENERATION v2.19- STATS =============\n",
      " Number of association rules generated : 12\n",
      " Total time ~ 1 ms\n",
      "===================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fpgrowth = Spmf(algorithm_name='FPGrowth_association_rules_with_lift',arguments=[0.25,0,1],\n",
    "                input_filename='new_dataset.txt',output_filename='fpgrowth_output.txt',spmf_bin_location_dir='/Users/smitdoshi/Downloads/')\n",
    "fpgrowth.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see here, for 40% support we can only get 2 rules - so, I tried it with 25% support and was able to get more rules, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-3f067f1fa4a9>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fp['Words'][index] = empty\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rules</th>\n",
       "      <th>Words</th>\n",
       "      <th>Support</th>\n",
       "      <th>Lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29 ==&gt; 5</td>\n",
       "      <td>lockdown,the</td>\n",
       "      <td>40027</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 ==&gt; 29</td>\n",
       "      <td>the,lockdown</td>\n",
       "      <td>40027</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78 ==&gt; 29</td>\n",
       "      <td>to,lockdown</td>\n",
       "      <td>32555</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29 ==&gt; 78</td>\n",
       "      <td>lockdown,to</td>\n",
       "      <td>32555</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73 ==&gt; 29</td>\n",
       "      <td>in,lockdown</td>\n",
       "      <td>27980</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29 ==&gt; 73</td>\n",
       "      <td>lockdown,in</td>\n",
       "      <td>27980</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>74 ==&gt; 29</td>\n",
       "      <td>and,lockdown</td>\n",
       "      <td>25837</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29 ==&gt; 74</td>\n",
       "      <td>lockdown,and</td>\n",
       "      <td>25837</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>48 ==&gt; 29</td>\n",
       "      <td>a,lockdown</td>\n",
       "      <td>25690</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29 ==&gt; 48</td>\n",
       "      <td>lockdown,a</td>\n",
       "      <td>25690</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rules         Words  Support  Lift\n",
       "0    29 ==> 5  lockdown,the    40027   1.0\n",
       "1    5 ==> 29  the,lockdown    40027   1.0\n",
       "2   78 ==> 29   to,lockdown    32555   1.0\n",
       "3   29 ==> 78   lockdown,to    32555   1.0\n",
       "4   73 ==> 29   in,lockdown    27980   1.0\n",
       "5   29 ==> 73   lockdown,in    27980   1.0\n",
       "8   74 ==> 29  and,lockdown    25837   1.0\n",
       "9   29 ==> 74  lockdown,and    25837   1.0\n",
       "10  48 ==> 29    a,lockdown    25690   1.0\n",
       "11  29 ==> 48    lockdown,a    25690   1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = pd.read_csv('fpgrowth_output.txt', sep='#',header=None)\n",
    "sup = fp[1].str.split(\":\", n = 1, expand = True)\n",
    "lift = fp[3].str.split(\":\", n = 1, expand = True)\n",
    "fp['Support'] = sup[1]\n",
    "fp['Lift'] = lift[1]\n",
    "fp.rename(columns = {0:'Rules'}, inplace = True)\n",
    "fp.drop(columns=[1,2,3],axis=1,inplace=True)\n",
    "fp.Rules = fp.Rules.str.strip()\n",
    "fp.Support = fp.Support.str.strip()\n",
    "fp.Lift = fp.Lift.str.strip()\n",
    "fp.Rules = fp.Rules.str.replace(\" ==> \",\"~\")\n",
    "fp.Rules = fp.Rules.str.replace(\" \",\",\")\n",
    "fp.Lift = fp.Lift.astype(float)\n",
    "fp.Support = fp.Support.astype(int)\n",
    "fp.Lift = np.round(fp.Lift,1)\n",
    "fp = fp.sort_values('Support',ascending=False,ignore_index=True)\n",
    "fp['Words'] = ''\n",
    "for index,rule in fp.Rules.iteritems():\n",
    "    empty = ''\n",
    "    for number in re.split('~|,',rule):\n",
    "        empty = empty + \",\" + GetKey(int(number))\n",
    "    fp['Words'][index] = empty\n",
    "fp.Words = fp.Words.str.lstrip(',')\n",
    "fp = fp[['Rules', 'Words', 'Support', 'Lift']]\n",
    "fp.Rules = fp.Rules.str.replace(\"~\",\" ==> \")\n",
    "fp[fp['Lift']== 1.0]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "SentimentalAnalysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
